{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dagsorden uge 13\n",
    "0. Gennemgå øvelse fra sidste uge.\n",
    "1. Gennemgå 12x mnist digits neural model\n",
    "2. Keras \n",
    "3. Øvelse\n",
    "4. Data wrangling\n",
    "5. Øvelse\n",
    "6. Eksamensprojekt udfordringer\n",
    "  - data collection\n",
    "      - api\n",
    "      - webscraping\n",
    "      - camera, microphone\n",
    "      - dataset\n",
    "      - pdf\n",
    "      - sheet, csv\n",
    "      - user input (post to flask app, cli args, etc)\n",
    "  - data wrangling\n",
    "      - manual overlook (eg: excel)\n",
    "        - misspelled values\n",
    "        - wrong columns\n",
    "        - breaking up or assembling column values\n",
    "      - remove rows if essential data is missing\n",
    "      - one-hot-encoding in order for the algorithms to understand\n",
    "      - [normalization, standardization, rescaling](https://medium.com/@swethalakshmanan14/how-when-and-why-should-you-normalize-standardize-rescale-your-data-3f083def38ff)\n",
    "        - (values scaled down to between 0 and 1), \n",
    "        - (values changed to have mean = 0  and standard div = 1) respectively\n",
    "      - remove columns\n",
    "  - data processing\n",
    "      - model fitting\n",
    "      - accuracy\n",
    "  - presentation\n",
    "      - filtering\n",
    "      - aggregation\n",
    "      - plotting\n",
    "        - diagrams\n",
    "      - conclusion (ml accuracy, predictions etc)\n",
    "      - flask server\n",
    "      \n",
    "Vigtigt at holde god balance mellem at bruge biblioteker og udvikle selv. Husk at angive kilder hvis i bruger andres kode. \n",
    "\n",
    "Husk: Eksamensformen er ændret. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### keras\n",
    "- [interactive tensorflow neural network demo](https://playground.tensorflow.org/#activation=linear&regularization=L1&batchSize=10&dataset=gauss&regDataset=reg-plane&learningRate=0.1&regularizationRate=0.1&noise=0&networkShape=4,2&seed=0.05661&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false)\n",
    "- [convolutional network with downsampling layers](https://www.cs.ryerson.ca/~aharley/vis/conv/flat.html)\n",
    "- Deep learning. Takes a lot of trial and error, to see what works best.\n",
    "  - lots of different activation functions and optimizers to choose from etc. keep it simple at first.\n",
    "- sequential model (most common, flows from left to right network layers)\n",
    "- Dense neural network for eg analysing images where each pixel is represented by an input neuron \n",
    "- Alternatives are \n",
    "  - convolutional neural network (good for finding edges in images - a window of some pixels are compared over the entire image)\n",
    "  - and recurrent neural networks) - Feeds the output back into the input of the neurons\n",
    "```python\n",
    "from keras.models import Sequential\n",
    "# model instance\n",
    "model = Sequence()\n",
    "# define each layer in the network\n",
    "from keras.layers import Dense # the simplest layer type\n",
    "```\n",
    "![](notebooks/images/dense_layer.png)\n",
    "### dense layer means a fully interconnected graph\n",
    "Each node in one layer is fully connected to each node in another layer.\n",
    "Use this for flexibility when we dont know what is going to happen in the data (no assumptions about the input)\n",
    "\n",
    "### Convolutional neural network\n",
    "![](images/convolutional_network.png)\n",
    "- filter: how many windows goving over the 2d data\n",
    "- kernel: how big are the windows width by height of \"pixels\"\n",
    "- a set of \"pixels\" (kernel) is transformed into a single value that represents the data in the kernel. This creates a pattern that is very suited for image recognition.\n",
    "- keras: layers.Conv2D(64,(3,3),activation='relu')\n",
    "- activation is the function used on the output after the convolution finishes\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.datasets import cifar10\n",
    "\n",
    "# CIFAR-10\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Target classes: numbers to text\n",
    "classes = {\n",
    "  0: 'airplane',\n",
    "  1: 'automobile',\n",
    "  2: 'bird',\n",
    "  3: 'cat',\n",
    "  4: 'deer',\n",
    "  5: 'dog',\n",
    "  6: 'frog',\n",
    "  7: 'horse',\n",
    "  8: 'ship',\n",
    "  9: 'truck'\n",
    "}\n",
    "\n",
    "# Visualize 20 random samples\n",
    "for i in np.random.randint(0, len(x_train)-1, 20):\n",
    "    # Get data\n",
    "    sample = x_train[i]\n",
    "    target = y_train[i][0]\n",
    "    # Set figure size and axis\n",
    "    plt.figure(figsize=(1.75, 1.75))\n",
    "    plt.axis('off')\n",
    "    # Show data\n",
    "    plt.imshow(sample)\n",
    "    plt.title(f'{classes[target]}')\n",
    "    #plt.savefig(f'./{i}.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1 hour\n",
    "[image classification](https://www.machinecurve.com/index.php/2019/12/31/exploring-the-keras-datasets/#cifar-10-small-image-classification). \n",
    "\n",
    "Use a Sequential model from keras with multiple convolutional 2d layers to classify the cifar10 images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data wrangling\n",
    "Look at the 10-4-2 Clustering Titanic example notebook for example of data wrangling\n",
    "- [sklearn.preprocessing](https://scikit-learn.org/stable/modules/preprocessing.html#encoding-categorical-features)\n",
    "- pd.get_dummies(data, columns)\n",
    "- df.dropna()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise data wrangling 45 min\n",
    "følg denne tutorial: [data wrangling](https://elitedatascience.com/python-data-wrangling-tutorial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
